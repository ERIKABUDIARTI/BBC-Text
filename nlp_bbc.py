# -*- coding: utf-8 -*-
"""NLP BBC.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1mhMX1l_9Eg1pomBEqT6-8BmCBQntnAXJ

Proyek NLP: **BBC Text Dataset**
- Nama:**ERIKA BUDIARTI**
- Email: erika.analytic@gmail.com
- Id Dicoding:erika_budiarti

# **Import Library**
"""

import pandas as pd
import numpy as np

import nltk
from nltk.corpus import stopwords

from sklearn.model_selection import train_test_split

import tensorflow as tf
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, Flatten, Dropout, Dense, LSTM, MaxPooling1D, Conv1D
from tensorflow.keras.optimizers import RMSprop
from tensorflow.keras.losses import SparseCategoricalCrossentropy

"""# Load Dataset"""

bbc_df = pd.read_csv('/content/bbc-text.csv')

bbc_df.shape

bbc_df.sample(10)

bbc_df.isna().sum()

bbc_df['category'].value_counts()

# Melakukan One-Hot encoding
category = pd.get_dummies(bbc_df.category)
bbc_new = pd.concat([bbc_df, category], axis=1)
bbc_new = bbc_new.drop(columns='category')
bbc_new.reset_index(inplace=True, drop=True)
bbc_new.shape

bbc_new.sample(10)

"""# **Penggunaan Stopwords**"""

nltk.download('stopwords')
STOPWORDS = set(stopwords.words())

texts = []
categories = []

for index, row in bbc_df.iterrows():
    categories.append(row['category'])
    text = row['text']
    for word in STOPWORDS:
        token = ' ' + word + ' '
        text = text.replace(token, ' ')
        text = text.replace(' ', ' ')
    texts.append(text)

"""# **Split Dataset**"""

X_train, X_val, y_train, y_val = train_test_split(texts, categories, test_size=0.2, random_state=42)

"""# **Penggunaan Tokenizer**"""

tokenizer = Tokenizer(num_words=10000, oov_token='<OOV>')
tokenizer.fit_on_texts(X_train)

word_index = tokenizer.word_index

train_sequences = tokenizer.texts_to_sequences(X_train)
train_padded = pad_sequences(train_sequences, maxlen=200, padding='post', truncating='post')

val_sequences = tokenizer.texts_to_sequences(X_val)
val_padded = pad_sequences(val_sequences, maxlen=200, padding='post', truncating='post')

categories_tokenizer = Tokenizer()
categories_tokenizer.fit_on_texts(categories)

train_catseq = np.array(categories_tokenizer.texts_to_sequences(y_train))
val_catseq = np.array(categories_tokenizer.texts_to_sequences(y_val))

"""# **Pembuatan Model**"""

model = tf.keras.Sequential([
    tf.keras.layers.Embedding(10000, 64, input_length=200),
    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32,return_sequences=True)),
    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32,return_sequences=True)),
    tf.keras.layers.Conv1D(64, 5, activation='relu'),
    tf.keras.layers.MaxPooling1D(pool_size=2),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dropout(0.5),
    tf.keras.layers.Dense(32, activation='relu'),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(6, activation='softmax')
])

model.summary()

loss = SparseCategoricalCrossentropy()

optimizer = RMSprop()

model.compile(loss=loss, optimizer=optimizer, metrics=['accuracy'])

class iCallback(tf.keras.callbacks.Callback):
  def __init__(self, model):
    self.model = model

  def on_epoch_end(self, epoch, logs={}):
    if (logs.get('val_accuracy') >= 0.91 and
        logs.get('accuracy') >= 0.91):
        self.model.stop_training = True

callback_model = iCallback(model)

history = model.fit(
    train_padded,
    train_catseq,
    epochs=20,
    batch_size=32,
    validation_data=(val_padded, val_catseq),
    callbacks=[callback_model],
    verbose=2
)

"""# **Accuracy & Loss Plot**"""

import matplotlib.pyplot as plt

# Data akurasi
train_accuracy = history.history['accuracy']
val_accuracy = history.history['val_accuracy']

# Data loss
train_loss = history.history['loss']
val_loss = history.history['val_loss']


fig, axes = plt.subplots(1, 2, figsize=(12, 6))

# Plot pertama (Akurasi)
axes[0].plot(train_accuracy, label='Train Accuracy')
axes[0].plot(val_accuracy, label='Validation Accuracy')
axes[0].set_title('Akurasi Model')
axes[0].set_xlabel('Epoch')
axes[0].set_ylabel('Accuracy')
axes[0].legend(loc='lower right')

# Plot kedua (Loss)
axes[1].plot(train_loss, label='Train Loss')
axes[1].plot(val_loss, label='Validation Loss')
axes[1].set_title('Loss Model')
axes[1].set_xlabel('Epoch')
axes[1].set_ylabel('Loss')
axes[1].legend(loc='upper right')

plt.tight_layout()
plt.show()